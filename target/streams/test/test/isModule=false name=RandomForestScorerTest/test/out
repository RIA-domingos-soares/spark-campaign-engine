[0m[[0minfo[0m] [0m[32mRandomForestScorerTest:[0m[0m
[0m[[0minfo[0m] [0m[32mThe RandomForest classifier[0m[0m
[0m[[0minfo[0m] [0m[32m- should process the Adult UCI dataset with accuracy[0m[0m
[0m[[0minfo[0m] [0m[32mThe RandomForest classifier[0m[0m
[0m[[0minfo[0m] [0m[31m- should process the gene selection dataset with accuracy *** FAILED ***[0m[0m
[0m[[0minfo[0m] [0m[31m  org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:[0m[0m
[0m[[0minfo[0m] [0m[31morg.apache.spark.SparkContext.<init>(SparkContext.scala:70)[0m[0m
[0m[[0minfo[0m] [0m[31mRandomForestScorerTest$$anon$1.<init>(RandomForestScorerTest.scala:19)[0m[0m
[0m[[0minfo[0m] [0m[31mRandomForestScorerTest.fixture(RandomForestScorerTest.scala:12)[0m[0m
[0m[[0minfo[0m] [0m[31mRandomForestScorerTest$$anonfun$1.apply$mcV$sp(RandomForestScorerTest.scala:25)[0m[0m
[0m[[0minfo[0m] [0m[31mRandomForestScorerTest$$anonfun$1.apply(RandomForestScorerTest.scala:23)[0m[0m
[0m[[0minfo[0m] [0m[31mRandomForestScorerTest$$anonfun$1.apply(RandomForestScorerTest.scala:23)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.Transformer.apply(Transformer.scala:22)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.Transformer.apply(Transformer.scala:20)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpecLike$$anon$1.apply(FlatSpecLike.scala:1647)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.Suite$class.withFixture(Suite.scala:1122)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpec.withFixture(FlatSpec.scala:1683)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpecLike$class.invokeWithFixture$1(FlatSpecLike.scala:1644)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpecLike$$anonfun$runTest$1.apply(FlatSpecLike.scala:1656)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpecLike$$anonfun$runTest$1.apply(FlatSpecLike.scala:1656)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.SuperEngine.runTestImpl(Engine.scala:306)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpecLike$class.runTest(FlatSpecLike.scala:1656)[0m[0m
[0m[[0minfo[0m] [0m[31morg.scalatest.FlatSpec.runTest(FlatSpec.scala:1683)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$7.apply(SparkContext.scala:1565)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1$$anonfun$apply$7.apply(SparkContext.scala:1561)[0m[0m
[0m[[0minfo[0m] [0m[31m  at scala.Option.foreach(Option.scala:236)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:1561)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:1548)[0m[0m
[0m[[0minfo[0m] [0m[31m  at scala.Option.foreach(Option.scala:236)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:1548)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:1600)[0m[0m
[0m[[0minfo[0m] [0m[31m  at org.apache.spark.SparkContext.<init>(SparkContext.scala:1507)[0m[0m
[0m[[0minfo[0m] [0m[31m  at RandomForestScorerTest$$anon$1.<init>(RandomForestScorerTest.scala:19)[0m[0m
[0m[[0minfo[0m] [0m[31m  ...[0m[0m
